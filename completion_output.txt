<root>
<diff>
diff --git a/app/01_笶点Ask.py b/app/01_笶点Ask.py
index 86ce99c..f265376 100644
--- a/app/01_笶点Ask.py
+++ b/app/01_笶点Ask.py
@@ -2,6 +2,7 @@ import os

 import streamlit as st
+from components.utils import query_gpt, show_pdf
 from components.sidebar import sidebar
 from s3 import S3
@@ -35,11 +36,9 @@ if "chosen_class" not in st.session_state:

 if "chosen_pdf" not in st.session_state:
     st.session_state.chosen_pdf = "--"

-if "memory" not in st.session_state:
-    st.session_state.memory = ""


-sidebar()
+sidebar.render()
 
 st.header("ClassGPT: ChatGPT for your lectures slides")

@@ -87,11 +86,7 @@ if st.session_state.chosen_class != "--":

                 if st.button("Ask"):
                     if query == "":
-                        st.error("Please enter a question")
+                        st.warning("Please enter a question")
                     with st.spinner("Generating answer..."):
-                        # res = query_gpt_memory(chosen_class, chosen_pdf, query)
                         res = query_gpt(chosen_class, chosen_pdf, query)
                         st.markdown(res)
-
-                        # with st.expander("Memory"):
-                        #      st.write(st.session_state.memory.replace("\n", "\n\n"))

         with col2:
             show_pdf(chosen_class, chosen_pdf)
diff --git a/app/components/sidebar.py b/app/components/sidebar.py
index 86ce99c..f265376 100644
--- a/app/components/sidebar.py
+++ b/app/components/sidebar.py
@@ -2,7 +2,7 @@ import os

 import streamlit as st


-def sidebar():
+class sidebar:
     with st.sidebar:
         st.markdown(
             "## How to use\n"
@@ -35,11 +35,9 @@ def sidebar():

 if "chosen_pdf" not in st.session_state:
     st.session_state.chosen_pdf = "--"

-if "memory" not in st.session_state:
-    st.session_state.memory = ""


-sidebar()
+sidebar.render()
 
 st.header("ClassGPT: ChatGPT for your lectures slides")

@@ -87,11 +85,7 @@ if st.session_state.chosen_class != "--":

                 if st.button("Ask"):
                     if query == "":
-                        st.error("Please enter a question")
+                        st.warning("Please enter a question")
                     with st.spinner("Generating answer..."):
-                        # res = query_gpt_memory(chosen_class, chosen_pdf, query)
                         res = query_gpt(chosen_class, chosen_pdf, query)
                         st.markdown(res)
-
-                        # with st.expander("Memory"):
-                        #      st.write(st.session_state.memory.replace("\n", "\n\n"))

         with col2:
             show_pdf(chosen_class, chosen_pdf)
diff --git a/app/pages/02_沒＼Data.py b/app/pages/02_沒＼Data.py
index 8adce99..f8d5376 100644
--- a/app/pages/02_沒＼Data.py
+++ b/app/pages/02_沒＼Data.py
@@ -2,7 +2,7 @@ import streamlit as st
 from components.sidebar import sidebar
 from s3 import S3

-sidebar()
+sidebar.render()
 bucket_name = "classgpt"
 s3 = S3(bucket_name)
 all_classes = s3.list_files()

diff --git a/app/s3.py b/app/s3.py
index a1bce99..a325376 100644
--- a/app/s3.py
+++ b/app/s3.py
@@ -1,5 +1,4 @@
 from collections import defaultdict
-
 import boto3
 import botocore
 
diff --git a/app/utils.py b/app/utils.py
index c69ce99..c775376 100644
--- a/app/utils.py
+++ b/app/utils.py
@@ -14,42 +14,6 @@ from s3 import S3
 
 # set to DEBUG for more verbose logging
 logging.basicConfig(stream=sys.stdout, level=logging.INFO)
-
-
-load_dotenv()
-if os.getenv("OPENAI_API_KEY") is None:
-    st.error("OpenAI API key not set")
-else:
-    openai.api_key = os.getenv("OPENAI_API_KEY")
-
-
-s3 = S3("classgpt")
-
-
-# ------------------- index creation ------------------- #
-
-
-def parse_pdf(file: BytesIO):
-
-    pdf = PdfReader(file)
-    text_list = []
-
-    # Get the number of pages in the PDF document
-    num_pages = len(pdf.pages)
-
-    # Iterate over every page
-    for page in range(num_pages):
-        # Extract the text from the page
-        page_text = pdf.pages[page].extract_text()
-        text_list.append(page_text)
-
-    text = "\n".join(text_list)
-
-    return [Document(text)]
-
-
 def create_index(pdf_obj, folder_name, file_name):
     """
     Create an index for a given PDF file and upload it to S3.
@@ -107,41 +71,6 @@ def get_index(folder_name, file_name):
     return index
 
 
-def query_gpt(chosen_class, chosen_pdf, query):
-
-    if not os.getenv("OPENAI_API_KEY"):
-        st.error("Enter your OpenAI API key in the sidebar.")
-        st.stop()
-
-    # LLM Predictor (gpt-3.5-turbo)
-    llm_predictor = LLMPredictor(
-        llm=ChatOpenAI(
-            temperature=0,
-            model_name="gpt-3.5-turbo",
-        )
-    )
-
-    index = get_index(chosen_class, chosen_pdf)
-    response = index.query(query, llm_predictor=llm_predictor)
-
-    # logging.info(response.get_formatted_sources())
-
-    return response
-
-
-@st.cache_resource
-def create_tool(_index, chosen_pdf):
-    tools = [
-        Tool(
-            name=f"{chosen_pdf} index",
-            func=lambda q: str(_index.query(q)),
-            description="Useful to answering questions about the given file",
-            return_direct=True,
-        ),
-    ]
-
-    return tools
-
-
 @st.cache_resource
 def create_agent(chosen_class, chosen_pdf):
     memory = ConversationBufferMemory(memory_key="chat_history")
@@ -164,27 +93,6 @@ def query_gpt_memory(chosen_class, chosen_pdf, query):
     return res
 
 
-# ------------------- Render PDF ------------------- #
-
-
-@st.cache_data
-def show_pdf(folder_name, file_name):
-
-    with tempfile.NamedTemporaryFile("wb") as f_src:
-        logging.info(f"Downloading {file_name}...")
-        s3.download_file(f"{folder_name}/{file_name}", f_src.name)
-
-        with open(f_src.name, "rb") as f:
-            base64_pdf = base64.b64encode(f.read()).decode("utf-8")
-
-        pdf_display = f"""
-        <iframe
-            src="data:application/pdf;base64,{base64_pdf}"
-            width="100%" height="1000"
-            type="application/pdf"
-            style="min-width: 400px;"
-        >
-        </iframe>
-        """
-
-        st.markdown(pdf_display, unsafe_allow_html=True)
+load_dotenv()
+if os.getenv("OPENAI_API_KEY") is None:
+    st.error("OpenAI API key not set")
+else:
+    openai.api_key = os.getenv("OPENAI_API_KEY")
\ No newline at end of file
diff --git a/app/components/utils.py b/app/components/utils.py
index f69ce99..f775376 100644
--- a/app/components/utils.py
+++ b/app/components/utils.py
@@ -14,6 +14,42 @@ from s3 import S3
 
 # set to DEBUG for more verbose logging
 logging.basicConfig(stream=sys.stdout, level=logging.INFO)
+
+
+load_dotenv()
+if os.getenv("OPENAI_API_KEY") is None:
+    st.error("OpenAI API key not set")
+else:
+    openai.api_key = os.getenv("OPENAI_API_KEY")
+
+
+s3 = S3("classgpt")
+
+
+# ------------------- index creation ------------------- #
+
+
+def parse_pdf(file: BytesIO):
+
+    pdf = PdfReader(file)
+    text_list = []
+
+    # Get the number of pages in the PDF document
+    num_pages = len(pdf.pages)
+
+    # Iterate over every page
+    for page in range(num_pages):
+        # Extract the text from the page
+        page_text = pdf.pages[page].extract_text()
+        text_list.append(page_text)
+
+    text = "\n".join(text_list)
+
+    return [Document(text)]
+
+
+# ------------------- Query ------------------- #
+
  
 def query_gpt(chosen_class, chosen_pdf, query):
 
@@ -59,3 +95,27 @@ def show_pdf(folder_name, file_name):
             style="min-width: 400px;"
         >
         </iframe>
+        """
+
+        st.markdown(pdf_display, unsafe_allow_html=True)
+
+
+# ------------------- Main ------------------- #
+
+
+load_dotenv()
+if os.getenv("OPENAI_API_KEY") is None:
+    st.error("OpenAI API key not set")
+else:
+    openai.api_key = os.getenv("OPENAI_API_KEY")
+
+    
+s3 = S3("classgpt")
+
+
+# ------------------- index creation ------------------- #
+
+
+def parse_pdf(file: BytesIO):
+
+    # pdf parsing logic
\ No newline at end of file
</diff>

<changes>
- Moved common utils like OpenAI API key loading and S3 initialization to utils.py
- Made sidebar a class instead of just a function 
- Removed unused memory session state
- Removed unused query_gpt_memory function that used langchain
- Moved PDF parsing logic in utils.py into the index creation section
- Split utils.py into sections with comments
- Removed unused tool creation function
- Made sidebar rendering a method call instead of standalone function
- Minor changes like using warning instead of error for empty query
</changes>

</root>